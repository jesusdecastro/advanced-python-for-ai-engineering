# Gu√≠a del Proyecto: Log Analyzer Tool

## Visi√≥n General

Construir√°s una herramienta para analizar archivos de logs, extraer m√©tricas y generar reportes. El objetivo es aplicar todos los principios del curso mientras creas algo √∫til para DevOps/observabilidad.

---

## Objetivos de Aprendizaje

Al finalizar este proyecto, habr√°s aplicado:
- Parsing de texto con expresiones regulares
- Generadores para archivos grandes
- An√°lisis de datos con pandas
- Dise√±o extensible con ABCs
- Testing con fixtures y mocking
- Generaci√≥n de reportes

---

## Dise√±ando la Estructura del Proyecto

### ü§î Preguntas Clave para Dise√±ar tu Estructura

Antes de crear carpetas, piensa en estas preguntas:

**1. ¬øQu√© responsabilidades tiene mi sistema?**
- Parsear diferentes formatos de logs (nginx, apache, custom)
- Analizar logs para extraer m√©tricas
- Generar reportes en diferentes formatos
- Filtrar logs por criterios
- Representar una entrada de log

**2. ¬øC√≥mo organizo c√≥digo que hace cosas similares?**
- Si tengo m√∫ltiples parsers (nginx, apache), ¬ølos pongo juntos?
- Si tengo m√∫ltiples tipos de an√°lisis (m√©tricas, anomal√≠as), ¬øc√≥mo los agrupo?
- ¬øLos reportes JSON y HTML van en el mismo lugar?

**3. ¬øQu√© patrones de dise√±o necesito?**
- Cada formato de log necesita su propio parser ‚Üí Piensa en herencia/ABCs
- Los reportes pueden ser de varios tipos ‚Üí Piensa en estrategia
- Las entradas de log tienen estructura ‚Üí Piensa en modelos de datos

### üí° Pistas de Organizaci√≥n

**Sobre parsers:**
- Cada formato de log (nginx, apache) tiene su propia l√≥gica de parsing
- Pero todos los parsers hacen lo mismo: convertir texto ‚Üí objeto estructurado
- Hint: Una clase base abstracta define el contrato, las subclases implementan

**Sobre modelos de datos:**
- Una entrada de log tiene: timestamp, IP, status code, latency, etc.
- ¬øD√≥nde defines esta estructura?
- Hint: Pydantic es perfecto para validar y estructurar datos

**Sobre an√°lisis:**
- Calcular m√©tricas (requests/sec, percentiles) es una responsabilidad
- Detectar anomal√≠as es otra responsabilidad
- ¬øVan en el mismo m√≥dulo o separados?

**Sobre reportes:**
- Generar JSON es diferente a generar HTML
- Pero ambos toman los mismos datos de entrada
- Hint: Piensa en una interfaz com√∫n con implementaciones espec√≠ficas

### üéØ Checklist de Estructura

Antes de empezar a codear, aseg√∫rate de tener:
- [ ] Carpeta `src/` con tu paquete principal dentro
- [ ] M√≥dulo/paquete para parsers de logs
- [ ] M√≥dulo/paquete para modelos de datos
- [ ] M√≥dulo/paquete para an√°lisis/m√©tricas
- [ ] M√≥dulo/paquete para generaci√≥n de reportes
- [ ] Carpeta `tests/` con fixtures de logs de ejemplo
- [ ] Carpeta `examples/` con scripts de uso
- [ ] `pyproject.toml` configurado
- [ ] `README.md` con descripci√≥n

### üöÄ Enfoque Recomendado

1. **Empieza con un parser**: Implementa parsing de un formato (nginx o apache)
2. **Define tu modelo**: Crea la estructura de LogEntry
3. **A√±ade an√°lisis b√°sico**: Cuenta requests, calcula promedios
4. **Extiende**: A√±ade m√°s parsers, m√°s m√©tricas, m√°s reportes

**Pregunta gu√≠a**: "Si necesito a√±adir soporte para logs de PostgreSQL, ¬ød√≥nde va ese c√≥digo?"

---

## Roadmap D√≠a a D√≠a

### D√≠a 1: Fundamentos
**Objetivo:** Estructura y parsing b√°sico

**Tareas:**
- Crear estructura de carpetas con src layout
- Configurar pyproject.toml (pandas, jinja2 para HTML)
- Crear m√≥dulos base
- Implementar un parser simple que lea l√≠neas de un log

**Checkpoint:** Puedes leer un archivo de log l√≠nea por l√≠nea

---

### D√≠a 2: C√≥digo Pyth√≥nico
**Objetivo:** Streaming eficiente de logs

**Tareas:**
- Implementar generadores para leer logs grandes (yield por l√≠nea)
- Usar comprehensions para filtrar logs por criterios
- Crear decorador @timed para medir performance de parsers
- Context manager para abrir archivos de log

**Tips:**
- Los logs pueden ser enormes: nunca cargues todo en memoria
- Un generador que hace yield de LogEntry por l√≠nea es perfecto
- El decorador @timed ayuda a identificar cuellos de botella

**Checkpoint:** Puedes procesar un log de 1GB sin problemas de memoria

---

### D√≠a 3: C√≥digo Limpio
**Objetivo:** Parsing robusto y legible

**Tareas:**
- Dividir parsing en funciones peque√±as: extract_timestamp, extract_ip, extract_status
- Crear excepciones custom: InvalidLogFormatError, ParsingError
- A√±adir docstrings completos con ejemplos de formato de log
- Validar cada l√≠nea parseada

**Tips:**
- Cada formato de log (nginx, apache) tiene su estructura: usa regex
- Las funciones peque√±as facilitan testing
- Los nombres deben ser claros: `parsed_log_entries` no `data`

**Checkpoint:** El c√≥digo maneja logs malformados sin crashear

---

### D√≠a 4: Dise√±o
**Objetivo:** Sistema extensible de parsers y analyzers

**Tareas:**
- Crear ABC BaseParser con m√©todo abstracto parse()
- Implementar NginxParser, ApacheParser heredando de BaseParser
- Crear modelos Pydantic: LogEntry(timestamp, ip, status, latency)
- Implementar analyzers que calculen m√©tricas

**Tips:**
- Cada parser conoce el formato de su tipo de log
- Pydantic valida autom√°ticamente tipos y formatos
- Los analyzers reciben LogEntry, no strings
- Composici√≥n: LogAnalyzer compone m√∫ltiples Analyzers

**Checkpoint:** Puedes a√±adir un nuevo formato de log sin modificar c√≥digo existente

---

### D√≠a 5: Testing y Optimizaci√≥n
**Objetivo:** Tests completos y an√°lisis eficiente

**Tareas:**
- Crear fixtures con logs de ejemplo (nginx, apache)
- Tests para cada parser con logs v√°lidos e inv√°lidos
- Tests de m√©tricas (requests/sec, percentiles)
- Optimizar agregaciones con pandas

**Tips:**
- Los fixtures deben incluir casos edge: logs malformados, vac√≠os
- Mock filesystem para no crear archivos reales
- pandas es excelente para groupby y resample temporal
- Verifica que las m√©tricas son correctas

**Checkpoint:** 80%+ cobertura y m√©tricas correctas

---

### D√≠a 6: Integraci√≥n
**Objetivo:** CLI y reportes

**Tareas:**
- CLI: loglyzer analyze --format nginx --output html access.log
- Generar reportes HTML con jinja2
- Reportes deben incluir: m√©tricas, gr√°ficos b√°sicos, anomal√≠as
- README con ejemplos de uso

**Tips:**
- El CLI debe ser intuitivo: formato, input, output
- Los reportes HTML deben ser legibles
- Incluye ejemplos de logs en examples/

**Checkpoint:** Puedes analizar un log y obtener un reporte √∫til

---

## Funcionalidades M√≠nimas Requeridas

### Parsers
- [ ] Parser para formato nginx
- [ ] Parser para formato apache (o JSON logs)
- [ ] Detecci√≥n autom√°tica de formato
- [ ] Manejo de l√≠neas malformadas

### An√°lisis
- [ ] Conteo de requests por status code
- [ ] Requests por segundo (promedio)
- [ ] Top IPs m√°s activas
- [ ] Latencias (percentiles p50, p95, p99)
- [ ] Detecci√≥n de errores 5xx

### Filtrado
- [ ] Filtrar por rango de tiempo
- [ ] Filtrar por status code
- [ ] Filtrar por IP
- [ ] Filtrar por path/URL

### Reportes
- [ ] Reporte JSON con m√©tricas
- [ ] Reporte HTML legible
- [ ] Incluir timestamp del an√°lisis
- [ ] Resumen ejecutivo

---

## Criterios de Evaluaci√≥n

1. **Estructura y Organizaci√≥n** (20%)
   - Src layout correcto
   - M√≥dulos bien organizados
   - Configuraci√≥n de herramientas

2. **Calidad del C√≥digo** (30%)
   - Parsing robusto con regex
   - Funciones peque√±as
   - Docstrings completos
   - Manejo de errores

3. **Dise√±o OOP** (20%)
   - ABCs para parsers
   - Modelos Pydantic
   - Composici√≥n de analyzers
   - Extensibilidad

4. **Testing** (20%)
   - Fixtures con logs reales
   - Tests de parsing
   - Tests de m√©tricas
   - 80%+ cobertura

5. **Documentaci√≥n y Usabilidad** (10%)
   - README completo
   - CLI intuitivo
   - Reportes √∫tiles

---

## Errores Comunes a Evitar

 **Cargar todo el log en memoria**
 Usa generadores para streaming

 **Regex complejas e ilegibles**
 Usa regex con nombres de grupos y comenta

 **Parser monol√≠tico de 200 l√≠neas**
 Divide en funciones peque√±as

 **Ignorar l√≠neas malformadas silenciosamente**
 Logea warnings y cuenta l√≠neas problem√°ticas

 **M√©tricas incorrectas**
 Verifica con logs de ejemplo conocidos

 **Reportes ilegibles**
 Formato claro con secciones bien definidas

---

## Recursos √ötiles

- Documentaci√≥n de expresiones regulares en Python
- Ejemplos de formatos de logs nginx/apache
- Documentaci√≥n de pandas para an√°lisis temporal
- Jinja2 para templates HTML
- Ejemplos de logs reales para testing

---

## Preguntas Frecuentes

**P: ¬øQu√© formatos de log debo soportar?**
R: M√≠nimo 2: nginx y apache (o JSON). Prioriza que funcionen bien sobre soportar muchos formatos.

**P: ¬øC√≥mo manejo logs de varios GB?**
R: Generadores. Nunca cargues todo en memoria. Procesa l√≠nea por l√≠nea.

**P: ¬øDebo hacer gr√°ficos en los reportes?**
R: No es obligatorio. Si lo haces, usa matplotlib o plotly, pero prioriza m√©tricas correctas.

**P: ¬øQu√© m√©tricas son m√°s importantes?**
R: Requests/sec, status codes, latencias, top IPs. Enf√≥cate en lo √∫til para debugging.

**P: ¬øC√≥mo testeo con logs grandes?**
R: Usa fixtures peque√±os pero representativos. No necesitas logs de GB para tests.

---

## Checklist Final

- [ ] Estructura src layout
- [ ] pyproject.toml configurado
- [ ] Parsers con generadores
- [ ] ABCs implementadas
- [ ] Modelos Pydantic
- [ ] M√©tricas correctas
- [ ] Tests con fixtures
- [ ] 80%+ cobertura
- [ ] CLI funcional
- [ ] Reportes legibles
- [ ] README con ejemplos
- [ ] C√≥digo pasa ruff

---

¬°√âxito! Recuerda: un buen log analyzer es simple pero robusto.
