{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Día 5: Optimización de pandas y DataFrames\n",
        "\n",
        "## Descripción General\n",
        "\n",
        "pandas es la biblioteca más popular para análisis de datos en Python, pero trabajar con grandes volúmenes de datos puede consumir mucha memoria y ser lento si no se optimiza correctamente. La clave está en elegir los tipos de datos (dtypes) apropiados, usar operaciones vectorizadas, y aplicar técnicas de optimización de memoria.\n",
        "\n",
        "En este notebook aprenderás cómo optimizar el uso de memoria en pandas, elegir dtypes eficientes, y aplicar operaciones vectorizadas para procesar datos de forma rápida y eficiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos de Aprendizaje\n",
        "\n",
        "Al finalizar este notebook, serás capaz de:\n",
        "\n",
        "1. Comprender cómo pandas almacena datos en memoria y por qué importa\n",
        "2. Elegir tipos de datos (dtypes) apropiados para reducir el uso de memoria\n",
        "3. Aplicar operaciones vectorizadas en lugar de bucles para mejorar el rendimiento\n",
        "4. Usar categorical dtypes para columnas con valores repetidos\n",
        "5. Medir y optimizar el uso de memoria de DataFrames"
      ]
    }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tipos de Datos (dtypes) en pandas\n",
        "\n",
        "### El Problema que Resuelve\n",
        "\n",
        "Por defecto, pandas usa tipos de datos genéricos que consumen más memoria de la necesaria. Por ejemplo:\n",
        "- Los enteros se almacenan como `int64` (8 bytes) incluso si los valores caben en `int8` (1 byte)\n",
        "- Los strings se almacenan como `object` dtype, que es ineficiente\n",
        "- Los valores categóricos se almacenan como strings repetidos\n",
        "\n",
        "### La Solución: Elegir dtypes Apropiados\n",
        "\n",
        "Elegir el dtype correcto puede reducir el uso de memoria en 50-90% sin perder información.\n",
        "\n",
        "### Aprendizaje Clave\n",
        "\n",
        "Los dtypes de pandas determinan cuánta memoria usa cada columna. Elegir dtypes apropiados (int8 vs int64, category vs object) puede reducir dramáticamente el uso de memoria.\n",
        "\n",
        "**Referencia oficial:** [pandas dtypes documentation](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create sample DataFrame with default dtypes\n",
        "df_default = pd.DataFrame({\n",
        "    'age': [25, 30, 35, 40, 45],\n",
        "    'score': [85, 90, 78, 92, 88],\n",
        "    'category': ['A', 'B', 'A', 'C', 'B']\n",
        "})\n",
        "\n",
        "print(\"Default dtypes:\")\n",
        "print(df_default.dtypes)\n",
        "print(f\"\\nMemory usage: {df_default.memory_usage(deep=True).sum()} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tipos de Datos Numéricos\n",
        "\n",
        "pandas ofrece varios tamaños de enteros y flotantes:\n",
        "\n",
        "**Enteros:**\n",
        "- `int8`: -128 a 127 (1 byte)\n",
        "- `int16`: -32,768 a 32,767 (2 bytes)\n",
        "- `int32`: -2,147,483,648 a 2,147,483,647 (4 bytes)\n",
        "- `int64`: rango muy grande (8 bytes) - **default**\n",
        "\n",
        "**Flotantes:**\n",
        "- `float32`: precisión simple (4 bytes)\n",
        "- `float64`: precisión doble (8 bytes) - **default**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BAD: Using default int64 for small values\n",
        "df_bad = pd.DataFrame({\n",
        "    'age': [25, 30, 35, 40, 45],  # Values fit in int8\n",
        "    'score': [85, 90, 78, 92, 88]  # Values fit in int8\n",
        "})\n",
        "\n",
        "print(\"BAD - Default dtypes:\")\n",
        "print(df_bad.dtypes)\n",
        "print(f\"Memory: {df_bad.memory_usage(deep=True).sum()} bytes\\n\")\n",
        "\n",
        "# GOOD: Using appropriate dtypes\n",
        "df_good = pd.DataFrame({\n",
        "    'age': pd.array([25, 30, 35, 40, 45], dtype='int8'),\n",
        "    'score': pd.array([85, 90, 78, 92, 88], dtype='int8')\n",
        "})\n",
        "\n",
        "print(\"GOOD - Optimized dtypes:\")\n",
        "print(df_good.dtypes)\n",
        "print(f\"Memory: {df_good.memory_usage(deep=True).sum()} bytes\")\n",
        "print(f\"\\nMemory reduction: {(1 - df_good.memory_usage(deep=True).sum() / df_bad.memory_usage(deep=True).sum()) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pregunta de Comprensión\n",
        "\n",
        "¿Por qué usar `int8` en lugar de `int64` cuando los valores son pequeños?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Categorical Dtypes\n",
        "\n",
        "### El Problema que Resuelve\n",
        "\n",
        "Cuando una columna tiene valores repetidos (como categorías, países, estados), almacenarlos como strings duplica la información y consume mucha memoria.\n",
        "\n",
        "### La Solución: Categorical Dtype\n",
        "\n",
        "El dtype `category` almacena los valores únicos una sola vez y usa códigos enteros para referenciarlos. Esto reduce dramáticamente el uso de memoria para columnas con cardinalidad baja.\n",
        "\n",
        "### Aprendizaje Clave\n",
        "\n",
        "Usa `category` dtype para columnas con valores repetidos. pandas almacena los valores únicos una vez y usa códigos enteros, reduciendo memoria y mejorando rendimiento.\n",
        "\n",
        "**Referencia oficial:** [pandas categorical data](https://pandas.pydata.org/docs/user_guide/categorical.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataFrame with repeated values\n",
        "n_rows = 100_000\n",
        "categories = ['Category A', 'Category B', 'Category C', 'Category D', 'Category E']\n",
        "\n",
        "# BAD: Using object dtype (strings)\n",
        "df_object = pd.DataFrame({\n",
        "    'category': np.random.choice(categories, n_rows)\n",
        "})\n",
        "\n",
        "print(\"BAD - Object dtype:\")\n",
        "print(f\"Dtype: {df_object['category'].dtype}\")\n",
        "print(f\"Memory: {df_object.memory_usage(deep=True).sum() / 1024:.2f} KB\\n\")\n",
        "\n",
        "# GOOD: Using category dtype\n",
        "df_category = pd.DataFrame({\n",
        "    'category': pd.Categorical(np.random.choice(categories, n_rows))\n",
        "})\n",
        "\n",
        "print(\"GOOD - Category dtype:\")\n",
        "print(f\"Dtype: {df_category['category'].dtype}\")\n",
        "print(f\"Memory: {df_category.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "print(f\"\\nMemory reduction: {(1 - df_category.memory_usage(deep=True).sum() / df_object.memory_usage(deep=True).sum()) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convertir a Categorical\n",
        "\n",
        "Puedes convertir columnas existentes a categorical:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert existing column to categorical\n",
        "df = pd.DataFrame({\n",
        "    'country': ['USA', 'Canada', 'USA', 'Mexico', 'Canada', 'USA'] * 1000\n",
        "})\n",
        "\n",
        "print(f\"Before conversion: {df.memory_usage(deep=True).sum()} bytes\")\n",
        "\n",
        "# Convert to categorical\n",
        "df['country'] = df['country'].astype('category')\n",
        "\n",
        "print(f\"After conversion: {df.memory_usage(deep=True).sum()} bytes\")\n",
        "print(f\"\\nCategories: {df['country'].cat.categories.tolist()}\")\n",
        "print(f\"Codes (first 10): {df['country'].cat.codes[:10].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Operaciones Vectorizadas\n",
        "\n",
        "### El Problema que Resuelve\n",
        "\n",
        "Los bucles de Python son lentos cuando se aplican a DataFrames. Iterar fila por fila es extremadamente ineficiente.\n",
        "\n",
        "### La Solución: Operaciones Vectorizadas\n",
        "\n",
        "pandas está construido sobre NumPy y soporta operaciones vectorizadas que se ejecutan en código C optimizado, siendo 10-100x más rápidas que bucles.\n",
        "\n",
        "### Aprendizaje Clave\n",
        "\n",
        "Evita bucles sobre DataFrames. Usa operaciones vectorizadas que se aplican a columnas completas de una vez, ejecutándose en código C optimizado.\n",
        "\n",
        "**Referencia oficial:** [pandas performance tips](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Create sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'price': np.random.rand(10_000) * 100,\n",
        "    'quantity': np.random.randint(1, 100, 10_000)\n",
        "})\n",
        "\n",
        "# BAD: Using loop\n",
        "start = time.time()\n",
        "total_loop = []\n",
        "for idx, row in df.iterrows():\n",
        "    total_loop.append(row['price'] * row['quantity'])\n",
        "df_loop = df.copy()\n",
        "df_loop['total'] = total_loop\n",
        "time_loop = time.time() - start\n",
        "\n",
        "# GOOD: Using vectorized operation\n",
        "start = time.time()\n",
        "df_vectorized = df.copy()\n",
        "df_vectorized['total'] = df['price'] * df['quantity']\n",
        "time_vectorized = time.time() - start\n",
        "\n",
        "print(f\"Loop time: {time_loop:.4f} seconds\")\n",
        "print(f\"Vectorized time: {time_vectorized:.4f} seconds\")\n",
        "print(f\"Speedup: {time_loop / time_vectorized:.1f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Operaciones Vectorizadas Comunes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    'a': [1, 2, 3, 4, 5],\n",
        "    'b': [10, 20, 30, 40, 50],\n",
        "    'c': [100, 200, 300, 400, 500]\n",
        "})\n",
        "\n",
        "# Arithmetic operations\n",
        "df['sum'] = df['a'] + df['b']\n",
        "df['product'] = df['a'] * df['b']\n",
        "df['ratio'] = df['c'] / df['b']\n",
        "\n",
        "# Conditional operations\n",
        "df['is_large'] = df['c'] > 250\n",
        "df['category'] = df['a'].apply(lambda x: 'high' if x > 3 else 'low')  # Use with caution\n",
        "\n",
        "# Better: Use np.where for conditionals\n",
        "df['category_vectorized'] = np.where(df['a'] > 3, 'high', 'low')\n",
        "\n",
        "print(df)"
      ]
    }
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pregunta de Comprensión\n",
        "\n",
        "¿Por qué las operaciones vectorizadas son más rápidas que los bucles?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Medición de Uso de Memoria\n",
        "\n",
        "### memory_usage() Method\n",
        "\n",
        "pandas proporciona el método `memory_usage()` para medir cuánta memoria usa cada columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'int_col': np.random.randint(0, 100, 1000),\n",
        "    'float_col': np.random.rand(1000),\n",
        "    'string_col': ['text'] * 1000,\n",
        "    'category_col': pd.Categorical(['A', 'B', 'C'] * 333 + ['A'])\n",
        "})\n",
        "\n",
        "# Memory usage by column\n",
        "print(\"Memory usage by column:\")\n",
        "print(df.memory_usage(deep=True))\n",
        "print(f\"\\nTotal memory: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "\n",
        "# Info method also shows memory\n",
        "print(\"\\nDataFrame info:\")\n",
        "df.info(memory_usage='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aprendizaje Clave\n",
        "\n",
        "Usa `memory_usage(deep=True)` para medir el uso real de memoria, especialmente para columnas object y category. El parámetro `deep=True` es esencial para obtener mediciones precisas.\n",
        "\n",
        "**Referencia oficial:** [pandas.DataFrame.memory_usage](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Estrategias de Optimización\n",
        "\n",
        "### Función de Optimización Automática\n",
        "\n",
        "Puedes crear una función que optimice automáticamente los dtypes de un DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Optimize DataFrame dtypes to reduce memory usage.\n",
        "    \n",
        "    :param df: DataFrame to optimize\n",
        "    :type df: pd.DataFrame\n",
        "    :return: Optimized DataFrame\n",
        "    :rtype: pd.DataFrame\n",
        "    \"\"\"\n",
        "    df_optimized = df.copy()\n",
        "    \n",
        "    for col in df_optimized.columns:\n",
        "        col_type = df_optimized[col].dtype\n",
        "        \n",
        "        # Optimize integers\n",
        "        if col_type == 'int64':\n",
        "            c_min = df_optimized[col].min()\n",
        "            c_max = df_optimized[col].max()\n",
        "            \n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                df_optimized[col] = df_optimized[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                df_optimized[col] = df_optimized[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                df_optimized[col] = df_optimized[col].astype(np.int32)\n",
        "        \n",
        "        # Optimize floats\n",
        "        elif col_type == 'float64':\n",
        "            df_optimized[col] = df_optimized[col].astype(np.float32)\n",
        "        \n",
        "        # Convert object to category if cardinality is low\n",
        "        elif col_type == 'object':\n",
        "            num_unique = df_optimized[col].nunique()\n",
        "            num_total = len(df_optimized[col])\n",
        "            \n",
        "            if num_unique / num_total < 0.5:  # Less than 50% unique values\n",
        "                df_optimized[col] = df_optimized[col].astype('category')\n",
        "    \n",
        "    return df_optimized\n",
        "\n",
        "# Test the optimization function\n",
        "df_test = pd.DataFrame({\n",
        "    'age': np.random.randint(18, 80, 10000),\n",
        "    'score': np.random.rand(10000) * 100,\n",
        "    'category': np.random.choice(['A', 'B', 'C', 'D'], 10000)\n",
        "})\n",
        "\n",
        "print(\"Before optimization:\")\n",
        "print(df_test.dtypes)\n",
        "print(f\"Memory: {df_test.memory_usage(deep=True).sum() / 1024:.2f} KB\\n\")\n",
        "\n",
        "df_optimized = optimize_dtypes(df_test)\n",
        "\n",
        "print(\"After optimization:\")\n",
        "print(df_optimized.dtypes)\n",
        "print(f\"Memory: {df_optimized.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "print(f\"\\nMemory reduction: {(1 - df_optimized.memory_usage(deep=True).sum() / df_test.memory_usage(deep=True).sum()) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicios Prácticos\n",
        "\n",
        "### Ejercicio 1: Optimizar Dtypes\n",
        "\n",
        "Optimiza el siguiente DataFrame reduciendo su uso de memoria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Optimize this DataFrame\n",
        "df_exercise = pd.DataFrame({\n",
        "    'user_id': np.arange(1, 10001),  # Values 1-10000\n",
        "    'age': np.random.randint(18, 100, 10000),  # Values 18-100\n",
        "    'score': np.random.randint(0, 100, 10000),  # Values 0-100\n",
        "    'country': np.random.choice(['USA', 'Canada', 'Mexico', 'UK'], 10000),\n",
        "    'status': np.random.choice(['active', 'inactive', 'pending'], 10000)\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df_exercise.dtypes)\n",
        "print(f\"Memory: {df_exercise.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
        "\n",
        "# TODO: Apply optimizations here\n",
        "# Hint: Convert integers to smaller types, convert strings to category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicio 2: Vectorizar Operaciones\n",
        "\n",
        "Reescribe el siguiente código usando operaciones vectorizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Vectorize this code\n",
        "df = pd.DataFrame({\n",
        "    'price': [100, 200, 150, 300, 250],\n",
        "    'quantity': [2, 1, 3, 2, 4],\n",
        "    'discount': [0.1, 0.2, 0.15, 0.0, 0.25]\n",
        "})\n",
        "\n",
        "# BAD: Using loop\n",
        "final_prices = []\n",
        "for idx, row in df.iterrows():\n",
        "    subtotal = row['price'] * row['quantity']\n",
        "    discount_amount = subtotal * row['discount']\n",
        "    final_price = subtotal - discount_amount\n",
        "    final_prices.append(final_price)\n",
        "\n",
        "df['final_price_loop'] = final_prices\n",
        "\n",
        "# TODO: Rewrite using vectorized operations\n",
        "# df['final_price_vectorized'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen\n",
        "\n",
        "En este notebook has aprendido:\n",
        "\n",
        "- Los dtypes de pandas determinan el uso de memoria\n",
        "- Elegir dtypes apropiados (int8 vs int64) reduce memoria significativamente\n",
        "- El dtype category es ideal para columnas con valores repetidos\n",
        "- Las operaciones vectorizadas son 10-100x más rápidas que bucles\n",
        "- Usa `memory_usage(deep=True)` para medir memoria real\n",
        "\n",
        "La optimización de pandas es esencial para trabajar con grandes volúmenes de datos de forma eficiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preguntas de Autoevaluación\n",
        "\n",
        "### 1. ¿Cuál es la diferencia entre int8 e int64?\n",
        "\n",
        "**Respuesta:** int8 usa 1 byte de memoria y puede almacenar valores de -128 a 127. int64 usa 8 bytes y puede almacenar valores mucho más grandes. Usar int8 cuando los valores son pequeños reduce el uso de memoria en 8x.\n",
        "\n",
        "### 2. ¿Cuándo usar el dtype category?\n",
        "\n",
        "**Respuesta:** Usa category cuando una columna tiene valores repetidos (baja cardinalidad). pandas almacena los valores únicos una vez y usa códigos enteros, reduciendo memoria y mejorando rendimiento.\n",
        "\n",
        "### 3. ¿Por qué evitar bucles en pandas?\n",
        "\n",
        "**Respuesta:** Los bucles de Python son lentos porque iteran elemento por elemento con overhead de interpretación. Las operaciones vectorizadas se ejecutan en código C optimizado, siendo 10-100x más rápidas.\n",
        "\n",
        "### 4. ¿Qué hace memory_usage(deep=True)?\n",
        "\n",
        "**Respuesta:** Mide el uso real de memoria incluyendo el contenido de columnas object y category. Sin deep=True, solo mide el tamaño de las referencias, no el contenido real.\n",
        "\n",
        "### 5. ¿Cómo optimizar un DataFrame automáticamente?\n",
        "\n",
        "**Respuesta:** Crea una función que analice cada columna y convierta enteros a tipos más pequeños, flotantes a float32, y columnas object con baja cardinalidad a category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recursos y Referencias Oficiales\n",
        "\n",
        "### Documentación Oficial\n",
        "\n",
        "- **pandas Documentation**: [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)\n",
        "  - Documentación completa de pandas\n",
        "\n",
        "- **pandas dtypes**: [https://pandas.pydata.org/docs/user_guide/basics.html#dtypes](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes)\n",
        "  - Guía sobre tipos de datos en pandas\n",
        "\n",
        "- **pandas categorical data**: [https://pandas.pydata.org/docs/user_guide/categorical.html](https://pandas.pydata.org/docs/user_guide/categorical.html)\n",
        "  - Documentación sobre categorical dtype\n",
        "\n",
        "- **pandas performance**: [https://pandas.pydata.org/docs/user_guide/enhancingperf.html](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)\n",
        "  - Guía de optimización de rendimiento\n",
        "\n",
        "### Guías y Tutoriales\n",
        "\n",
        "- **pandas memory optimization**: [https://pythonspeed.com/articles/pandas-load-less-data/](https://pythonspeed.com/articles/pandas-load-less-data/)\n",
        "  - Guía sobre reducción de uso de memoria\n",
        "\n",
        "- **Efficient pandas**: [https://realpython.com/fast-flexible-pandas/](https://realpython.com/fast-flexible-pandas/)\n",
        "  - Tutorial sobre pandas eficiente\n",
        "\n",
        "### Notas Importantes\n",
        "\n",
        "- Todos los enlaces están actualizados a partir de 2026\n",
        "- La optimización de dtypes puede reducir memoria en 50-90%\n",
        "- Usa category para columnas con menos del 50% de valores únicos\n",
        "- Las operaciones vectorizadas son siempre preferibles a bucles\n",
        "- Mide memoria con memory_usage(deep=True) para resultados precisos"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
