# Error Handling y Logging

## Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Excepciones Espec√≠ficas vs Gen√©ricas](#1-excepciones-espec√≠ficas-vs-gen√©ricas)
3. [Logging Efectivo](#2-logging-efectivo)
4. [Configuraci√≥n de Logging](#3-configuraci√≥n-de-logging)
5. [Contexto en Errores](#4-contexto-en-errores)
6. [Resumen](#resumen-de-principios)

---

## Introducci√≥n

El manejo de errores y logging son pr√°cticas fundamentales que determinan si tu c√≥digo es debuggeable en producci√≥n o una caja negra imposible de diagnosticar.

**Referencia principal**: Martin, R. C. (2008). *Clean Code: A Handbook of Agile Software Craftsmanship*. Prentice Hall. Chapter 7: Error Handling.

### Contexto: Por Qu√© Importa

**Problema real en Data/IA**:
Est√°s entrenando un modelo con un dataset de 10 millones de registros. A las 3 AM (despu√©s de 6 horas de procesamiento) el script falla con "KeyError: 'age'". No sabes en qu√© registro fall√≥, qu√© datos ten√≠a, ni por qu√©. Tienes que empezar de cero.

**Ejemplo concreto**:
Tu funci√≥n de preprocesamiento falla con "ValueError" pero no sabes:
- ¬øEn qu√© archivo fall√≥?
- ¬øQu√© valor caus√≥ el error?
- ¬øCu√°ntos registros proces√≥ antes de fallar?
- ¬øFue un error puntual o sistem√°tico?

**Consecuencias de NO usarlo**:
- **Debugging imposible**: Errores sin contexto, no sabes qu√© pas√≥
- **Tiempo perdido**: Reejecutar procesos largos desde cero
- **Datos perdidos**: No sabes qu√© registros se procesaron correctamente
- **Producci√≥n fr√°gil**: Errores en producci√≥n sin forma de diagnosticar

### Principio Fundamental

> "Clean code is simple and direct. Clean code reads like well-written prose. Clean code never obscures the designer's intent but rather is full of crisp abstractions and straightforward lines of control."
>
> ‚Äî Grady Booch

El manejo de errores es parte del c√≥digo, no un a√±adido. Debe ser tan limpio y claro como el resto del c√≥digo.

---

### El Concepto

**Definici√≥n t√©cnica**:
El manejo de errores y logging son pr√°cticas complementarias: el manejo de errores controla el flujo cuando algo sale mal, mientras que el logging registra informaci√≥n sobre la ejecuci√≥n para debugging y monitoreo.

**C√≥mo funciona internamente**:
1. **Excepciones**: Python usa try/except para capturar y manejar errores
2. **Logging**: M√≥dulo `logging` registra eventos con diferentes niveles de severidad
3. **Contexto**: Ambos deben proporcionar informaci√≥n suficiente para diagnosticar problemas

**Terminolog√≠a clave**:
- **Exception**: Objeto que representa un error en tiempo de ejecuci√≥n
- **Logging level**: Severidad del mensaje (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- **Stack trace**: Secuencia de llamadas que llevaron al error
- **Context**: Informaci√≥n adicional sobre el estado cuando ocurri√≥ el error

---

## 1. Excepciones Espec√≠ficas vs Gen√©ricas

### Por Qu√© Importa

Capturar excepciones gen√©ricas (`except Exception`) oculta errores y hace el debugging imposible. Las excepciones espec√≠ficas te permiten manejar solo los errores que realmente puedes resolver.

---

### Ejemplo Incorrecto

```python
def load_model_config(config_path: str) -> dict:
    """Load model configuration - manejo gen√©rico."""
    try:
        with open(config_path) as f:
            config = json.load(f)
        return config
    except Exception as e:  # ¬°Demasiado gen√©rico!
        print(f"Error: {e}")
        return {}
```

**Problemas**:

- Captura TODOS los errores (incluso KeyboardInterrupt)
- No distingue entre archivo no encontrado vs JSON inv√°lido
- `print()` en vez de logging
- Retorna dict vac√≠o silenciosamente (oculta el problema)

---

### Ejemplo Correcto

```python
import logging
from pathlib import Path
from typing import Dict, Any

logger = logging.getLogger(__name__)

def load_model_config(config_path: str) -> Dict[str, Any]:
    """
    Load model configuration from JSON file.
    
    :param config_path: Path to configuration file
    :type config_path: str
    :return: Configuration dictionary
    :rtype: Dict[str, Any]
    :raises FileNotFoundError: If config file doesn't exist
    :raises json.JSONDecodeError: If config file is not valid JSON
    :raises ValueError: If config file is empty
    """
    path = Path(config_path)
    
    # Check file exists
    if not path.exists():
        logger.error(f"Configuration file not found: {config_path}")
        raise FileNotFoundError(f"Config file not found: {config_path}")
    
    # Load and parse JSON
    try:
        with open(path) as f:
            config = json.load(f)
    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON in {config_path}: {e}")
        raise
    
    # Validate not empty
    if not config:
        logger.error(f"Configuration file is empty: {config_path}")
        raise ValueError(f"Config file is empty: {config_path}")
    
    logger.info(f"Successfully loaded config from {config_path}")
    return config
```

**Ventajas**:

- Excepciones espec√≠ficas para cada tipo de error
- Logging con contexto claro
- No oculta errores (los propaga)
- F√°cil de debuggear

---

## 2. Logging Efectivo

### Por Qu√© Importa

El logging es tu ventana al comportamiento del c√≥digo en producci√≥n. Sin logging adecuado, los errores son imposibles de diagnosticar.

**Referencia**: Python Logging HOWTO: <https://docs.python.org/3/howto/logging.html>

---

### Niveles de Logging

```python
import logging

# DEBUG: Informaci√≥n detallada para diagnosticar problemas
logging.debug("Processing record 1523 with features: [0.5, 0.3, 0.8]")

# INFO: Confirmaci√≥n de que las cosas funcionan como se espera
logging.info("Model training completed successfully in 45.2 seconds")

# WARNING: Algo inesperado pero no cr√≠tico
logging.warning("Missing 'age' field in 15 records, using default value")

# ERROR: Error que impide una operaci√≥n espec√≠fica
logging.error("Failed to save model checkpoint: disk full")

# CRITICAL: Error grave que puede detener la aplicaci√≥n
logging.critical("Database connection lost, cannot continue")
```

---

### Ejemplo Incorrecto

```python
def process_dataset(data_path: str):
    """Process dataset - logging pobre."""
    print("Starting")  # No nivel, no contexto
    
    data = pd.read_csv(data_path)
    print(f"Loaded {len(data)} rows")  # print() en vez de logging
    
    # Procesa datos...
    cleaned = data.dropna()
    print("Cleaned")  # ¬øCu√°ntos se eliminaron?
    
    return cleaned
```

**Problemas**:

- Usa `print()` en vez de logging
- Sin niveles de severidad
- Sin contexto √∫til
- No se puede controlar el output

---

### Ejemplo Correcto

```python
import logging
from pathlib import Path
import pandas as pd

logger = logging.getLogger(__name__)

def process_dataset(data_path: str) -> pd.DataFrame:
    """
    Process dataset with comprehensive logging.
    
    :param data_path: Path to CSV file
    :type data_path: str
    :return: Cleaned dataframe
    :rtype: pd.DataFrame
    :raises FileNotFoundError: If data file doesn't exist
    :raises pd.errors.EmptyDataError: If file is empty
    """
    logger.info(f"Starting dataset processing: {data_path}")
    
    # Load data
    try:
        data = pd.read_csv(data_path)
        logger.info(f"Loaded {len(data)} rows, {len(data.columns)} columns from {data_path}")
    except FileNotFoundError:
        logger.error(f"Data file not found: {data_path}")
        raise
    except pd.errors.EmptyDataError:
        logger.error(f"Data file is empty: {data_path}")
        raise
    
    # Clean data
    initial_rows = len(data)
    cleaned = data.dropna()
    removed_rows = initial_rows - len(cleaned)
    
    if removed_rows > 0:
        removal_pct = (removed_rows / initial_rows) * 100
        logger.warning(
            f"Removed {removed_rows} rows ({removal_pct:.1f}%) with missing values"
        )
    else:
        logger.info("No missing values found")
    
    logger.info(f"Processing complete: {len(cleaned)} rows remaining")
    return cleaned
```

**Ventajas**:

- Usa logging module con niveles apropiados
- Contexto rico (n√∫meros, porcentajes, paths)
- F√°cil de filtrar por nivel
- Se puede redirigir a archivos

---

## 3. Configuraci√≥n de Logging

### Por Qu√© Importa

Una configuraci√≥n adecuada de logging al inicio de tu aplicaci√≥n asegura que todos los mensajes se registren consistentemente.

---

### Setup B√°sico para Scripts

```python
import logging
from pathlib import Path

def setup_logging(log_file: str = "pipeline.log", level: int = logging.INFO):
    """
    Configure logging for the application.
    
    :param log_file: Path to log file
    :type log_file: str
    :param level: Logging level
    :type level: int
    """
    # Create logs directory if needed
    log_path = Path(log_file)
    log_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Configure logging
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()  # Also print to console
        ]
    )
    
    logging.info(f"Logging configured: level={logging.getLevelName(level)}, file={log_file}")

# Uso
if __name__ == "__main__":
    setup_logging("logs/training.log", level=logging.INFO)
    
    logger = logging.getLogger(__name__)
    logger.info("Starting training pipeline")
    # ... resto del c√≥digo
```

---

### Setup Avanzado para Producci√≥n

```python
import logging
import logging.handlers
from pathlib import Path

def setup_production_logging(
    log_dir: str = "logs",
    level: int = logging.INFO,
    max_bytes: int = 10 * 1024 * 1024,  # 10MB
    backup_count: int = 5
):
    """
    Configure production-grade logging with rotation.
    
    :param log_dir: Directory for log files
    :type log_dir: str
    :param level: Logging level
    :type level: int
    :param max_bytes: Max size per log file
    :type max_bytes: int
    :param backup_count: Number of backup files to keep
    :type backup_count: int
    """
    # Create log directory
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    
    # Create formatters
    detailed_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    simple_formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # File handler with rotation
    file_handler = logging.handlers.RotatingFileHandler(
        f"{log_dir}/app.log",
        maxBytes=max_bytes,
        backupCount=backup_count
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(detailed_formatter)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(level)
    console_handler.setFormatter(simple_formatter)
    
    # Error file handler (only errors)
    error_handler = logging.handlers.RotatingFileHandler(
        f"{log_dir}/errors.log",
        maxBytes=max_bytes,
        backupCount=backup_count
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(detailed_formatter)
    
    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)
    root_logger.addHandler(error_handler)
    
    logging.info("Production logging configured")
```

---

## 4. Contexto en Errores

### Por Qu√© Importa

Un error sin contexto es imposible de debuggear. Siempre incluye informaci√≥n sobre qu√© estabas procesando cuando fall√≥.

---

### Ejemplo Incorrecto

```python
def train_model(data):
    """Train model - sin contexto en errores."""
    for i, row in data.iterrows():
        try:
            prediction = model.predict(row)
        except Exception as e:
            print(f"Error: {e}")  # ¬øEn qu√© fila? ¬øQu√© datos?
            continue
```

**Problemas**:

- No sabes en qu√© fila fall√≥
- No sabes qu√© datos causaron el error
- Usa `print()` en vez de logging
- Captura excepciones gen√©ricas

---

### Ejemplo Correcto

```python
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

def train_model(data: pd.DataFrame) -> List[float]:
    """
    Train model with detailed error context.
    
    :param data: Training data
    :type data: pd.DataFrame
    :return: List of predictions
    :rtype: List[float]
    """
    predictions = []
    errors = 0
    
    for idx, row in data.iterrows():
        try:
            prediction = model.predict(row)
            predictions.append(prediction)
        except ValueError as e:
            errors += 1
            logger.error(
                f"Prediction failed for row {idx}: {e}. "
                f"Row data: {row.to_dict()}"
            )
            predictions.append(None)
        except Exception as e:
            errors += 1
            logger.critical(
                f"Unexpected error at row {idx}: {type(e).__name__}: {e}. "
                f"Row data: {row.to_dict()}",
                exc_info=True  # Include full stack trace
            )
            raise
    
    if errors > 0:
        error_rate = (errors / len(data)) * 100
        logger.warning(f"Completed with {errors} errors ({error_rate:.1f}% error rate)")
    else:
        logger.info(f"Successfully processed all {len(data)} rows")
    
    return predictions
```

**Ventajas**:

- Incluye √≠ndice de fila donde fall√≥
- Incluye datos de la fila problem√°tica
- Distingue entre errores esperados y cr√≠ticos
- Stack trace completo para errores inesperados

---

## Aprendizaje Clave

### Puntos Cr√≠ticos a Recordar

1. **Excepciones espec√≠ficas**: Captura solo los errores que puedes manejar
2. **Logging con contexto**: Incluye informaci√≥n que ayude a diagnosticar
3. **Niveles apropiados**: DEBUG para detalles, INFO para progreso, WARNING para problemas menores, ERROR para fallos
4. **No ocultes errores**: Si no puedes manejar un error, d√©jalo propagarse
5. **Configura logging**: Setup al inicio con formato consistente

---

### C√≥mo Desarrollar Intuici√≥n

**Preg√∫ntate**: "Si este c√≥digo falla a las 3 AM, ¬øtendr√© suficiente informaci√≥n para debuggear?"
- NO ‚Üí A√±ade m√°s logging y contexto
- S√ç ‚Üí Est√° bien

**Preg√∫ntate**: "¬øPuedo manejar este error de forma significativa?"
- S√ç ‚Üí Captura la excepci√≥n espec√≠fica y man√©jala
- NO ‚Üí D√©jala propagarse (no uses `except Exception`)

**Preg√∫ntate**: "¬øQu√© nivel de logging es apropiado?"
- Informaci√≥n de debugging detallada ‚Üí DEBUG
- Progreso normal ‚Üí INFO
- Algo raro pero no cr√≠tico ‚Üí WARNING
- Operaci√≥n fall√≥ ‚Üí ERROR
- Sistema en peligro ‚Üí CRITICAL

---

### Cu√°ndo Usar Cada Nivel

**DEBUG cuando**:
- Valores de variables intermedias
- Flujo detallado de ejecuci√≥n
- Solo √∫til durante desarrollo

**INFO cuando**:
- Inicio/fin de operaciones importantes
- Progreso de procesos largos
- Confirmaci√≥n de √©xito

**WARNING cuando**:
- Datos faltantes pero hay fallback
- Configuraci√≥n sub√≥ptima
- Uso de valores por defecto

**ERROR cuando**:
- Operaci√≥n fall√≥ pero el programa contin√∫a
- Archivo no se pudo procesar
- Request a API fall√≥

**CRITICAL cuando**:
- Sistema no puede continuar
- P√©rdida de conexi√≥n cr√≠tica
- Corrupci√≥n de datos

---

## Resumen de Principios

El manejo de errores y logging efectivos son fundamentales en Data/IA:

1. **Usa excepciones espec√≠ficas**: Captura solo lo que puedes manejar
2. **Logging con contexto**: Incluye informaci√≥n √∫til para debugging
3. **Niveles apropiados**: DEBUG, INFO, WARNING, ERROR, CRITICAL seg√∫n severidad
4. **Configura al inicio**: Setup consistente con formato claro
5. **No ocultes errores**: Si no puedes manejar, propaga

**Regla de oro**: Si tu c√≥digo falla en producci√≥n a las 3 AM, el logging debe tener suficiente informaci√≥n para que puedas diagnosticar el problema sin reejecutar.

---

## Referencias

1. Martin, R. C. (2008). *Clean Code: A Handbook of Agile Software Craftsmanship*. Prentice Hall. Chapter 7: Error Handling.
2. Python Logging HOWTO: <https://docs.python.org/3/howto/logging.html>
3. Python Logging Cookbook: <https://docs.python.org/3/howto/logging-cookbook.html>
4. PEP 282 ‚Äì A Logging System: <https://peps.python.org/pep-0282/>
5. Effective Python: 90 Specific Ways to Write Better Python (2nd ed.). Brett Slatkin. Item 75: Use repr Strings for Debugging Output.

---

## Ejercicio Pr√°ctico Individual

Refactoriza el siguiente c√≥digo para a√±adir manejo de errores apropiado y logging:

```python
def process_data_file(file_path):
    data = pd.read_csv(file_path)
    data = data.dropna()
    data['normalized'] = (data['value'] - data['value'].mean()) / data['value'].std()
    data.to_csv('output.csv')
    return len(data)
```

**Pistas**:
- ¬øQu√© puede fallar en cada paso?
- ¬øQu√© informaci√≥n necesitar√≠as para debuggear?
- ¬øQu√© nivel de logging es apropiado para cada operaci√≥n?

---

## üèãÔ∏è Ejercicio Grupal: A√±adir Error Handling y Logging a Pipeline

**Objetivo**: Aplicar principios de error handling y logging a un pipeline de ML real.

**Contexto**: Has heredado un script de entrenamiento que falla frecuentemente en producci√≥n, pero nadie sabe por qu√©. El equipo pierde horas reejecutando procesos y debuggeando sin informaci√≥n.

**Tiempo estimado**: 30-45 minutos

**Din√°mica**:
1. **An√°lisis individual** (5 min): Identifica puntos de fallo
2. **Discusi√≥n en grupo** (10 min): Planifiquen estrategia de logging
3. **Refactorizaci√≥n colaborativa** (20 min): A√±adan error handling y logging
4. **Presentaci√≥n** (10 min): Compartan mejoras con otros grupos

---

### C√≥digo a Refactorizar

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib

def train_pipeline(data_path, model_path, test_size=0.2):
    # Load data
    data = pd.read_csv(data_path)
    
    # Prepare features
    X = data.drop('target', axis=1)
    y = data['target']
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    # Train model
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    
    # Evaluate
    train_acc = accuracy_score(y_train, model.predict(X_train))
    test_acc = accuracy_score(y_test, model.predict(X_test))
    
    # Save model
    joblib.dump(model, model_path)
    
    return {'train_acc': train_acc, 'test_acc': test_acc}

if __name__ == '__main__':
    result = train_pipeline('data.csv', 'model.pkl')
    print(result)
```

---

### Instrucciones para el Grupo

**Paso 1: Identificar Puntos de Fallo** (10 minutos)

Discutan y anoten:

1. ¬øQu√© puede fallar en cada paso?
2. ¬øQu√© informaci√≥n necesitar√≠an para diagnosticar cada fallo?
3. ¬øQu√© errores son recuperables vs cr√≠ticos?
4. ¬øQu√© nivel de logging es apropiado para cada operaci√≥n?

**Paso 2: Dise√±ar Estrategia** (10 minutos)

Decidan en grupo:

1. ¬øQu√© excepciones espec√≠ficas capturar?
2. ¬øQu√© informaci√≥n incluir en cada log?
3. ¬øC√≥mo configurar el logging?
4. ¬øQu√© validaciones a√±adir?

**Paso 3: Refactorizar** (20 minutos)

Dividan el trabajo:

- **Persona 1**: Setup de logging y carga de datos
- **Persona 2**: Preparaci√≥n de features y validaci√≥n
- **Persona 3**: Entrenamiento y evaluaci√≥n
- **Persona 4**: Guardado de modelo y funci√≥n main

**Criterios de √âxito**:

- [ ] Logging configurado al inicio
- [ ] Excepciones espec√≠ficas para cada tipo de error
- [ ] Contexto rico en cada log (n√∫meros, paths, etc.)
- [ ] Niveles de logging apropiados
- [ ] Validaciones de datos
- [ ] Informaci√≥n suficiente para debuggear sin reejecutar
- [ ] No se ocultan errores cr√≠ticos

---

### Pistas

**Para Carga de Datos**:
```python
# Capturar errores espec√≠ficos
try:
    data = pd.read_csv(data_path)
    logger.info(f"Loaded {len(data)} rows from {data_path}")
except FileNotFoundError:
    logger.error(f"Data file not found: {data_path}")
    raise
except pd.errors.EmptyDataError:
    logger.error(f"Data file is empty: {data_path}")
    raise
```

**Para Validaci√≥n**:
```python
# Validar antes de procesar
if 'target' not in data.columns:
    logger.error(f"Missing 'target' column. Available: {data.columns.tolist()}")
    raise ValueError("Target column not found")

if len(data) < 100:
    logger.warning(f"Small dataset: only {len(data)} rows")
```

**Para Entrenamiento**:
```python
# Log progreso y m√©tricas
logger.info("Starting model training")
model.fit(X_train, y_train)
logger.info(f"Training complete: {len(X_train)} samples")

train_acc = accuracy_score(y_train, model.predict(X_train))
logger.info(f"Train accuracy: {train_acc:.4f}")
```

**Para Guardado**:
```python
# Manejar errores de escritura
try:
    joblib.dump(model, model_path)
    logger.info(f"Model saved to {model_path}")
except IOError as e:
    logger.error(f"Failed to save model: {e}")
    raise
```

---

### Preguntas para Reflexi√≥n

Despu√©s de refactorizar, discutan:

1. ¬øQu√© errores pueden diagnosticar ahora que antes no?
2. ¬øQu√© informaci√≥n de logging es m√°s valiosa?
3. ¬øHay alg√∫n trade-off entre logging detallado y performance?
4. ¬øC√≥mo cambiar√≠a el logging para producci√≥n vs desarrollo?
5. ¬øQu√© errores deber√≠an ser recuperables vs cr√≠ticos?

---
