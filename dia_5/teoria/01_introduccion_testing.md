# IntroducciÃ³n al Testing

## ğŸ¯ Contexto: Por QuÃ© Importa

**Problema real en Data/IA**:

Tu pipeline de limpieza de datos funciona correctamente con el CSV de desarrollo. Lo despliegas a producciÃ³n el viernes por la tarde. El lunes descubres que el CSV de producciÃ³n tenÃ­a una columna con valores vacÃ­os que tu funciÃ³n `parse_float` no manejaba â€” no lanzÃ³ error, simplemente convirtiÃ³ `""` a `0.0`. Tu modelo se entrenÃ³ con ceros donde deberÃ­a haber NaN. Los resultados del fin de semana son basura. Tres dÃ­as de cÃ³mputo perdidos.

**Ejemplo concreto**:

Un equipo desarrolla un procesador de texto para NLP. La funciÃ³n `normalize_text` hace lowercase, elimina acentos y colapsa espacios. Funciona con los 20 ejemplos del notebook. En producciÃ³n recibe un documento con caracteres Unicode exÃ³ticos (emojis, caracteres CJK, zero-width spaces). La funciÃ³n no falla â€” simplemente produce texto corrupto que contamina el embedding store. Sin tests, nadie se entera hasta que los usuarios reportan resultados irrelevantes semanas despuÃ©s.

**Consecuencias de NO testear**:

- **Errores silenciosos**: Funciones que no fallan pero producen resultados incorrectos â€” el peor tipo de bug en data pipelines
- **Miedo a refactorizar**: Sin tests, cada cambio es una ruleta rusa. El cÃ³digo se vuelve legacy en semanas
- **Debugging en producciÃ³n**: Sin tests locales, el primer lugar donde descubres bugs es en producciÃ³n, a las 3 AM
- **Regresiones**: Arreglas un bug hoy, introduces otro maÃ±ana en la misma funciÃ³n. Sin tests, no lo sabes
- **Onboarding lento**: Un nuevo miembro del equipo no puede verificar que sus cambios no rompen nada

## ğŸ“š El Concepto

### Principio Fundamental

> "Legacy code is simply code without tests."
>
> â€” Michael Feathers, *Working Effectively with Legacy Code* (Prentice Hall, 2004), Preface

Si tu cÃ³digo no tiene tests, ya es legacy â€” aunque lo hayas escrito ayer. Los tests no son un lujo ni una tarea para "cuando haya tiempo". Son la herramienta que te permite cambiar cÃ³digo con confianza, detectar bugs antes de que lleguen a producciÃ³n, y dormir tranquilo sabiendo que tu pipeline hace lo que debe.

### DefiniciÃ³n tÃ©cnica

El **testing de software** es la prÃ¡ctica de verificar automÃ¡ticamente que tu cÃ³digo se comporta como esperas. Un test es una funciÃ³n que ejecuta tu cÃ³digo con inputs conocidos y verifica que los outputs son correctos. En Python, el framework estÃ¡ndar de facto es **pytest**.

### CÃ³mo funciona

1. Escribes una funciÃ³n de test que llama a tu cÃ³digo con inputs especÃ­ficos
2. Usas `assert` para verificar que el resultado es el esperado
3. Ejecutas `pytest` que descubre y ejecuta todos los tests automÃ¡ticamente
4. pytest reporta quÃ© tests pasaron (verde) y cuÃ¡les fallaron (rojo) con detalle del error

### TerminologÃ­a clave

- **Unit test**: Test que verifica una funciÃ³n o clase aislada, sin dependencias externas
- **Functional test**: Test que verifica un flujo completo de entrada â†’ salida, con I/O real
- **Test fixture**: CÃ³digo de preparaciÃ³n que configura el estado necesario para un test (datos, ficheros, objetos)
- **Mock**: Objeto falso que simula una dependencia externa (fichero, API, BD) para aislar lo que quieres testear
- **Cobertura (coverage)**: Porcentaje de lÃ­neas de tu cÃ³digo que son ejecutadas por al menos un test
- **PatrÃ³n AAA**: Arrange (preparar datos), Act (ejecutar cÃ³digo), Assert (verificar resultado)
- **RegresiÃ³n**: Bug que aparece en cÃ³digo que antes funcionaba, tÃ­picamente al hacer cambios

## La PirÃ¡mide de Testing

### Por QuÃ© Importa

Sin una estrategia clara de quÃ© testear y cÃ³mo, los equipos tienden a dos extremos: no testear nada ("no hay tiempo") o testear todo con tests E2E lentos y frÃ¡giles que nadie mantiene. La pirÃ¡mide de testing es un modelo mental que te dice cuÃ¡ntos tests de cada tipo necesitas.

En data engineering y AI, la base de la pirÃ¡mide (unit tests) es especialmente importante porque las funciones de transformaciÃ³n de datos son puras y fÃ¡ciles de testear â€” y son exactamente donde los bugs silenciosos causan mÃ¡s daÃ±o.

### La PirÃ¡mide Visual

```
        /â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
       /     E2E Tests       \        Pocos, lentos, frÃ¡giles
      /   (pipeline entero)   \       Solo camino crÃ­tico
     /â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
    /   Integration Tests       \     Algunos, velocidad media
   /   (componentes juntos)      \    Con mocks parciales
  /â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
 /   Functional Tests (I/O)        \  Varios por flujo I/O
/   (fichero entra â†’ fichero sale)  \ Con tmp_path, sin mocks
/â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
/         Unit Tests                    \ Muchos, rÃ¡pidos, estables
/ (una funciÃ³n aislada, sin I/O)         \ La base de todo
/â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
```

### Tabla Comparativa

| Tipo | Â¿QuÃ© prueba? | Ejemplo en AI/Data | Velocidad | Cantidad |
|------|--------------|-------------------|-----------|----------|
| Unit | Una funciÃ³n aislada | `clean_text(" Hello ")` â†’ `"hello"` | âš¡ ms | Muchos (70-80%) |
| Functional | Entrada â†’ Salida real | Fichero CSV entra â†’ fichero JSON sale | ğŸƒ ms-seg | Varios (15-20%) |
| Integration | Componentes juntos | Leer CSV + limpiar + validar schema | ğŸƒ segundos | Pocos (5-10%) |
| E2E | Flujo completo | Pipeline entero desde API hasta output | ğŸ¢ minutos | MÃ­nimos (1-5%) |

## âŒ Ejemplo Incorrecto

```python
# test_pipeline.py â€” Un solo test E2E gigante que intenta probarlo todo
import subprocess

def test_entire_pipeline():
    """Test que ejecuta el pipeline entero y verifica el output."""
    # Requiere: BD Postgres levantada, S3 con datos, modelo descargado...
    result = subprocess.run(
        ["python", "run_pipeline.py", "--config", "prod_config.yaml"],
        capture_output=True,
    )
    assert result.returncode == 0
    # Â¿QuÃ© fallÃ³ exactamente si returncode != 0? No sabemos.
    # Â¿CuÃ¡nto tarda? 15 minutos.
    # Â¿Funciona en el portÃ¡til de un nuevo dev? No.
```

**Problemas**:

- Test lento (minutos): nadie lo ejecuta durante el desarrollo
- FrÃ¡gil: falla si la BD no estÃ¡ levantada, si S3 estÃ¡ caÃ­do, si cambiÃ³ el schema...
- Sin diagnÃ³stico: si falla, solo sabes que "algo" no funcionÃ³ â€” no quÃ©
- No aislado: un error en la funciÃ³n `clean_text` y un error en la conexiÃ³n a BD producen el mismo sÃ­ntoma
- Imposible de ejecutar en CI sin infraestructura completa

## âœ… Ejemplo Correcto

```python
# La pirÃ¡mide en la prÃ¡ctica:

# ======== UNIT TESTS (muchos, rÃ¡pidos, aislados) ========

def test_clean_text_removes_extra_spaces():
    """Una funciÃ³n, un comportamiento, un assert."""
    assert clean_text("hello   world") == "hello world"

def test_clean_text_handles_empty_string():
    assert clean_text("") == ""

def test_validate_email_rejects_missing_at():
    assert validate_email("invalidemail.com") is False

# ======== FUNCTIONAL TESTS (algunos, I/O real) ========

def test_csv_processing_produces_valid_output(tmp_path):
    """Entrada real â†’ proceso â†’ salida real."""
    input_file = tmp_path / "input.csv"
    input_file.write_text("name,age\nAlice,30\n")
    
    output_file = tmp_path / "output.csv"
    process_csv(str(input_file), str(output_file))
    
    result = output_file.read_text()
    assert "Alice" in result

# ======== INTEGRATION TESTS (pocos, componentes juntos) ========

def test_pipeline_reads_and_transforms(mock_db, tmp_path):
    """Dos componentes reales trabajando juntos."""
    # mock_db simula la BD, pero el CSV es real
    ...

# ======== E2E (mÃ­nimos, solo camino crÃ­tico) ========
# Se ejecutan solo en CI, no en cada commit
```

**Ventajas**:

- Los unit tests se ejecutan en milisegundos â€” los corres constantemente
- Si falla `test_clean_text_removes_extra_spaces`, sabes exactamente quÃ© se rompiÃ³
- No necesitas infraestructura para el 80% de tus tests
- Cada test es independiente â€” un fallo no contamina otros
- Los nuevos miembros del equipo pueden ejecutar tests desde el primer dÃ­a

## ğŸ’¡ Aprendizaje Clave

**Puntos crÃ­ticos a recordar**:

1. Los tests no son opcionales â€” son la red de seguridad que te permite cambiar cÃ³digo con confianza
2. La pirÃ¡mide de testing te guÃ­a: muchos unit tests rÃ¡pidos en la base, pocos E2E en la cima
3. En data/AI, los bugs silenciosos (resultados incorrectos sin error) son los mÃ¡s peligrosos

**CÃ³mo desarrollar intuiciÃ³n**:

- **PregÃºntate**: "Â¿QuÃ© tipo de test necesita este cÃ³digo?"
  - Si es una funciÃ³n pura (input â†’ output, sin I/O) â†’ Unit test
  - Si lee/escribe ficheros â†’ Functional test con `tmp_path`
  - Si llama a API externa â†’ Unit test con mock
  - Si es el flujo completo â†’ E2E (solo para camino crÃ­tico)

**CuÃ¡ndo usar / NO usar**:

- âœ… **Usar tests cuando**:
  - Escribes funciones de transformaciÃ³n de datos
  - Implementas validaciones o parsers
  - Tienes lÃ³gica de negocio que puede cambiar
  - Quieres refactorizar sin miedo
  
- âŒ **NO necesitas tests para**:
  - Wrappers triviales de una lÃ­nea sin lÃ³gica
  - CÃ³digo de configuraciÃ³n estÃ¡tico
  - Scripts de un solo uso

**Referencia oficial**: [pytest Documentation - Getting Started](https://docs.pytest.org/en/stable/getting-started.html)

## Resumen

Los tests son tu primera lÃ­nea de defensa contra bugs en producciÃ³n. La pirÃ¡mide de testing te dice que la mayorÃ­a de tus tests deben ser unit tests rÃ¡pidos y aislados (70-80%), complementados con functional tests para I/O (15-20%), algunos integration tests (5-10%), y mÃ­nimos E2E (1-5%). En data engineering y AI, donde los bugs silenciosos pueden contaminar datasets enteros, los tests no son un lujo â€” son esenciales.
